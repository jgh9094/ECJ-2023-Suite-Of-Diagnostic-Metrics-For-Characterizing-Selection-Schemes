#!/bin/bash
########## Define Resources Needed with SBATCH Lines ##########

#SBATCH --time=00:10:00               # limit of wall clock time - how long the job will run (same as -t)
#SBATCH --array=1-8                   # number of jobs being created, each with its array id
#SBATCH --mem=1G                      # memory required per node - amount of memory (in gigs)
#SBATCH --job-name bst-dia            # you can give your job a name for easier identification (same as -J)
#SBATCH --account=devolab             # research group account being used

##################################
# Setup required dependencies
##################################
module load GCCcore/11.2.0; module load Python/3.9.6; pip3 install pandas;

##################################
# Setup relevant directories
##################################
DATA_DIR=/mnt/gs21/scratch/herna383/ECJ-2023/
DUMP_DIR=/mnt/gs21/scratch/herna383/ECJ-2023-DUMP/

##################################
# Treatments
##################################

DIAGNOSTIC_EXPLOITATION_RATE=0
DIAGNOSTIC_ORDERED_EXPLOITATION=1
DIAGNOSTIC_CONTRADICTORY_OBJECTIVES=2
DIAGNOSTIC_MULTIPATH_EXPLORATION=3

##################################
# Valley vars
##################################

VALLEY=0

####################################################################

if [ ${SLURM_ARRAY_TASK_ID} -eq 1 ] ; then
  DIAGNOSTIC=${DIAGNOSTIC_EXPLOITATION_RATE}
  OFFSET=0
  EXPERIMENT=0
  DUMP=${DUMP_DIR}/BASE_DIAGNOSTICS/EXPLOITATION_RATE/


elif [ ${SLURM_ARRAY_TASK_ID} -eq 2 ] ; then
  DIAGNOSTIC=${DIAGNOSTIC_ORDERED_EXPLOITATION}
  OFFSET=500
  EXPERIMENT=0
  DUMP=${DUMP_DIR}/BASE_DIAGNOSTICS/ORDERED_EXPLOITATION/


elif [ ${SLURM_ARRAY_TASK_ID} -eq 3 ] ; then
  DIAGNOSTIC=${DIAGNOSTIC_CONTRADICTORY_OBJECTIVES}
  OFFSET=1000
  EXPERIMENT=0
  DUMP=${DUMP_DIR}/BASE_DIAGNOSTICS/CONTRADICTORY_OBJECTIVES/


elif [ ${SLURM_ARRAY_TASK_ID} -eq 4 ] ; then
  DIAGNOSTIC=${DIAGNOSTIC_MULTIPATH_EXPLORATION}
  OFFSET=1500
  EXPERIMENT=0
  DUMP=${DUMP_DIR}/BASE_DIAGNOSTICS/MULTIPATH_EXPLORATION/


elif [ ${SLURM_ARRAY_TASK_ID} -eq 5 ] ; then
  DIAGNOSTIC=${DIAGNOSTIC_EXPLOITATION_RATE}
  OFFSET=2000
  VALLEY=1
  EXPERIMENT=1
  DUMP=${DUMP_DIR}/MVC_DIAGNOSTICS/EXPLOITATION_RATE/

elif [ ${SLURM_ARRAY_TASK_ID} -eq 6 ] ; then
  DIAGNOSTIC=${DIAGNOSTIC_ORDERED_EXPLOITATION}
  OFFSET=2500
  VALLEY=1
  EXPERIMENT=1
  DUMP=${DUMP_DIR}/MVC_DIAGNOSTICS/ORDERED_EXPLOITATION/

elif [ ${SLURM_ARRAY_TASK_ID} -eq 7 ] ; then
  DIAGNOSTIC=${DIAGNOSTIC_CONTRADICTORY_OBJECTIVES}
  OFFSET=3000
  VALLEY=1
  EXPERIMENT=1
  DUMP=${DUMP_DIR}/MVC_DIAGNOSTICS/CONTRADICTORY_OBJECTIVES/

elif [ ${SLURM_ARRAY_TASK_ID} -eq 8 ] ; then
  DIAGNOSTIC=${DIAGNOSTIC_MULTIPATH_EXPLORATION}
  OFFSET=3500
  VALLEY=1
  EXPERIMENT=1
  DUMP=${DUMP_DIR}/MVC_DIAGNOSTICS/MULTIPATH_EXPLORATION/

else
  echo "${SLURM_ARRAY_TASK_ID} from failed to launch" >> /mnt/ls15/scratch/users/herna383/ps-coh-failtolaunch.txt
fi

# make DUMP directory
mkdir -p ${DUMP}

####################################################################

echo "python3 diagnostic-best.py ${DATA_DIR} ${DUMP} ${DIAGNOSTIC} ${OFFSET} ${VALLEY} ${EXPERIMENT} > run.log" > ./cmd-coh.txt

python3 diagnostic-best.py ${DATA_DIR} ${DUMP} ${DIAGNOSTIC} ${OFFSET} ${VALLEY} ${EXPERIMENT}